{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Credit Card Applications\n",
    "<p>Commercial banks receive a lot of applications for credit cards. Many of them get rejected for many reasons. <br>\n",
    "Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. \n",
    "<br>\n",
    "<br>\n",
    "In this notebook, we will build an automatic credit card approval predictor using machine learning techniques, just like the real banks do.</p>\n",
    "<p><img src=\"https://cdn.pixabay.com/photo/2016/07/15/21/07/credit-card-1520400_960_720.jpg\" alt=\"Credit card being held in hand\"></p>\n",
    "<br>\n",
    "<p>\n",
    "We'll use the Credit Card Approval dataset from the UCI Machine Learning Repository. You can find the dataset from \"..\\Datasets\\cc_approvals.data\" </p>\n",
    "<br>\n",
    "Notebook Outline:  \n",
    "\n",
    "- First, we will start off by loading and viewing the dataset.  \n",
    "\n",
    "- We will see that the dataset has a mixture of both numerical and non-numerical features, that it contains values from different ranges, plus that it contains a number of missing entries. \n",
    "\n",
    "- We will have to preprocess the dataset to ensure the machine learning model we choose can make good predictions.  \n",
    "- After our data is in good shape, we will do some exploratory data analysis to build our intuitions.  \n",
    "- Finally, we will build a machine learning model that can predict if an individual's application for a credit card will be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load the data and viewing it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = '..\\Datasets\\cc_approvals.data'\n",
    "df = pd.read_csv(url, header=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Inspecting:**  \n",
    "The probable features in a typical credit card application are <br>\n",
    "- *Gender*,\n",
    "- *Age*, \n",
    "- *Debt*, \n",
    "- *Married*, \n",
    "- ...\n",
    "- *ApprovalStatus*  \n",
    "\n",
    "Before doing preprocessing things let's learn about the dataset a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Age', 'Debt', 'Married', 'BankCustomer', 'EducationLevel',\n",
       "       'Ethnicity', 'YearsEmployed', 'PriorDefault', 'Employed', 'CreditScore',\n",
       "       'DriversLicense', 'Citizen', 'ZipCode', 'Income', 'ApprovalStatus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [\"Gender\", \"Age\", \"Debt\", \n",
    "            \"Married\", \"BankCustomer\", \n",
    "            \"EducationLevel\", \"Ethnicity\", \n",
    "            \"YearsEmployed\", \"PriorDefault\", \n",
    "            \"Employed\", \"CreditScore\",\n",
    "             \"DriversLicense\", \"Citizen\", \n",
    "             \"ZipCode\", \"Income\", \"ApprovalStatus\"]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Debt  YearsEmployed  CreditScore         Income\n",
      "count  690.000000     690.000000    690.00000     690.000000\n",
      "mean     4.758725       2.223406      2.40000    1017.385507\n",
      "std      4.978163       3.346513      4.86294    5210.102598\n",
      "min      0.000000       0.000000      0.00000       0.000000\n",
      "25%      1.000000       0.165000      0.00000       0.000000\n",
      "50%      2.750000       1.000000      0.00000       5.000000\n",
      "75%      7.207500       2.625000      3.00000     395.500000\n",
      "max     28.000000      28.500000     67.00000  100000.000000 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Gender          690 non-null    object \n",
      " 1   Age             690 non-null    object \n",
      " 2   Debt            690 non-null    float64\n",
      " 3   Married         690 non-null    object \n",
      " 4   BankCustomer    690 non-null    object \n",
      " 5   EducationLevel  690 non-null    object \n",
      " 6   Ethnicity       690 non-null    object \n",
      " 7   YearsEmployed   690 non-null    float64\n",
      " 8   PriorDefault    690 non-null    object \n",
      " 9   Employed        690 non-null    object \n",
      " 10  CreditScore     690 non-null    int64  \n",
      " 11  DriversLicense  690 non-null    object \n",
      " 12  Citizen         690 non-null    object \n",
      " 13  ZipCode         690 non-null    object \n",
      " 14  Income          690 non-null    int64  \n",
      " 15  ApprovalStatus  690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>ApprovalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.25</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.00</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>2.00</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.04</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.29</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender    Age    Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
       "685      b  21.08  10.085       y            p              e         h   \n",
       "686      a  22.67   0.750       u            g              c         v   \n",
       "687      a  25.25  13.500       y            p             ff        ff   \n",
       "688      b  17.92   0.205       u            g             aa         v   \n",
       "689      b  35.00   3.375       u            g              c         h   \n",
       "\n",
       "     YearsEmployed PriorDefault Employed  CreditScore DriversLicense Citizen  \\\n",
       "685           1.25            f        f            0              f       g   \n",
       "686           2.00            f        t            2              t       g   \n",
       "687           2.00            f        t            1              t       g   \n",
       "688           0.04            f        f            0              f       g   \n",
       "689           8.29            f        f            0              t       g   \n",
       "\n",
       "    ZipCode  Income ApprovalStatus  \n",
       "685   00260       0              -  \n",
       "686   00200     394              -  \n",
       "687   00200       1              -  \n",
       "688   00280     750              -  \n",
       "689   00000       0              -  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary stats\n",
    "df_describe = df.describe()\n",
    "print(df_describe,'\\n')\n",
    "\n",
    "df_info = df.info()\n",
    "print(df_info,'\\n')\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Splitting the dataset:**  \n",
    "We should split the data into train and test set to prepare the data for two different phases of machine learning modelling.  \n",
    "<br>\n",
    "Also features like *ZipCode*, *DriverLicense* are not as important as the other features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# drop unnecessary\n",
    "df = df.drop(['DriversLicense', 'ZipCode'], axis=1)\n",
    "\n",
    "# split the df\n",
    "df_train, df_test = train_test_split(df, test_size=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Handling missing values:**\n",
    "- The dataset also contains values from several ranges. Some features have a values range of 0-28, some have a range of 2-67, and some have another range.  \n",
    "Apart from theese, we can get useful statistical information (like *mean*, *median*, *max* etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>Income</th>\n",
       "      <th>ApprovalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>b</td>\n",
       "      <td>27.25</td>\n",
       "      <td>1.665</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>h</td>\n",
       "      <td>5.085</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>9</td>\n",
       "      <td>g</td>\n",
       "      <td>827</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>b</td>\n",
       "      <td>37.33</td>\n",
       "      <td>2.665</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>0.165</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>a</td>\n",
       "      <td>38.58</td>\n",
       "      <td>5.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>13.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>a</td>\n",
       "      <td>20.67</td>\n",
       "      <td>1.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>v</td>\n",
       "      <td>2.085</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>g</td>\n",
       "      <td>2503</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>a</td>\n",
       "      <td>23.00</td>\n",
       "      <td>11.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>0.500</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>g</td>\n",
       "      <td>551</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender    Age    Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
       "144      b  27.25   1.665       u            g             cc         h   \n",
       "645      b  37.33   2.665       u            g             cc         v   \n",
       "72       a  38.58   5.000       u            g             cc         v   \n",
       "235      a  20.67   1.835       u            g              q         v   \n",
       "37       a  23.00  11.750       u            g              x         h   \n",
       "\n",
       "     YearsEmployed PriorDefault Employed  CreditScore Citizen  Income  \\\n",
       "144          5.085            t        t            9       g     827   \n",
       "645          0.165            f        f            0       g     501   \n",
       "72          13.500            t        f            0       g       0   \n",
       "235          2.085            t        t            5       g    2503   \n",
       "37           0.500            t        t            2       g     551   \n",
       "\n",
       "    ApprovalStatus  \n",
       "144              +  \n",
       "645              -  \n",
       "72               -  \n",
       "235              +  \n",
       "37               +  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# replace \"?\" 's with NaN in both of sets\n",
    "df_train = df_train.replace('?', np.NaN)\n",
    "df_test = df_test.replace('?', np.NaN)\n",
    "\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender            11\n",
      "Age               12\n",
      "Debt               0\n",
      "Married            6\n",
      "BankCustomer       6\n",
      "EducationLevel     9\n",
      "Ethnicity          9\n",
      "YearsEmployed      0\n",
      "PriorDefault       0\n",
      "Employed           0\n",
      "CreditScore        0\n",
      "Citizen            0\n",
      "Income             0\n",
      "ApprovalStatus     0\n",
      "dtype: int64\n",
      "Gender            1\n",
      "Age               0\n",
      "Debt              0\n",
      "Married           0\n",
      "BankCustomer      0\n",
      "EducationLevel    0\n",
      "Ethnicity         0\n",
      "YearsEmployed     0\n",
      "PriorDefault      0\n",
      "Employed          0\n",
      "CreditScore       0\n",
      "Citizen           0\n",
      "Income            0\n",
      "ApprovalStatus    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramaz\\AppData\\Local\\Temp\\ipykernel_18364\\2492568824.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_train.fillna(df_train.mean(), inplace=True)\n",
      "C:\\Users\\ramaz\\AppData\\Local\\Temp\\ipykernel_18364\\2492568824.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_test.fillna(df_test.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Impute the missing values with mean imputation\n",
    "df_train.fillna(df_train.mean(), inplace=True)\n",
    "df_test.fillna(df_test.mean(), inplace=True)\n",
    "\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender            0\n",
      "Age               0\n",
      "Debt              0\n",
      "Married           0\n",
      "BankCustomer      0\n",
      "EducationLevel    0\n",
      "Ethnicity         0\n",
      "YearsEmployed     0\n",
      "PriorDefault      0\n",
      "Employed          0\n",
      "CreditScore       0\n",
      "Citizen           0\n",
      "Income            0\n",
      "ApprovalStatus    0\n",
      "dtype: int64\n",
      "Gender            0\n",
      "Age               0\n",
      "Debt              0\n",
      "Married           0\n",
      "BankCustomer      0\n",
      "EducationLevel    0\n",
      "Ethnicity         0\n",
      "YearsEmployed     0\n",
      "PriorDefault      0\n",
      "Employed          0\n",
      "CreditScore       0\n",
      "Citizen           0\n",
      "Income            0\n",
      "ApprovalStatus    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Iterate columns\n",
    "for col in df_train.columns:\n",
    "    # Check if the column is of object type\n",
    "    if df_train[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        df_train = df_train.fillna(df_train[col].value_counts().index[0])\n",
    "        df_test = df_test.fillna(df_train[col].value_counts().index[0])\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Preprocessing the data:**  \n",
    "Processing the missing values are done.  \n",
    "<br>\n",
    "There is still some minor preprocessing stuffs.  \n",
    "1. Convert the non-numeric data into numeric.  \n",
    "1. Scale the feature values to a uniform range.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set train and test stuffs sets independently\n",
    "df_train = pd.get_dummies(df_train)\n",
    "df_test = pd.get_dummies(df_test)\n",
    "\n",
    "# reindex\n",
    "df_test = df_test.reindex(columns=df_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are only left with one final preprocessing step of scaling before we can fit a machine learning model to the data.  \n",
    "<br>\n",
    "Now, let's try to understand what these scaled values mean in the real world. Let's use CreditScore as an example. The credit score of a person is their creditworthiness based on their credit history. The higher this number, the more financially trustworthy a person is considered to be. So, a CreditScore of 1 is the highest since we're rescaling all the values to the range of 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X_train, y_train = df_train.iloc[:, :-1].values, df_train.iloc[:, [-1]].values\n",
    "X_test, y_test = df_test.iloc[:, :-1].values, df_test.iloc[:, [-1]].values\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Fitting Machine Learning Model:**  \n",
    "This task is about classification task. So I'll use classification models like _Logistic Regression_.  \n",
    "  \n",
    "At this part you may be asking yourselft to _Which model should I pick?_  \n",
    "Although we can measure correlation, that is outside the scope of this notebook, so we'll rely on our intuition that they indeed are correlated for now. Because of this correlation, we'll take advantage of the fact that generalized linear models perform well in these cases. Let's start our machine learning modeling with a Logistic Regression model (a generalized linear model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate a LogisticRegression with default parameters.\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(rescaledX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Making predictions and evaluating performance:**  \n",
    "How well does our model perform?  \n",
    "  \n",
    "We will now evaluate our model on the test set with respect to [classification accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy).  \n",
    "But we will also take a look the model's [confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Classifier:1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# make some predictions\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# get the accuracy score from logreg model\n",
    "print(f'Accuracy of Logistic Regression Classifier:{logreg.score(rescaledX_test, y_test)}')\n",
    "\n",
    "# get the accuracy from confusion matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "578ce5a4903d7b45920c2d79663ce2541e7c0226009dc3f8451a28c8417bba54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
